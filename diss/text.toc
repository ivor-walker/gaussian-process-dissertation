\contentsline {section}{\numberline {1}TODO Introduction}{4}{section.1}%
\contentsline {section}{\numberline {2}Defining the Gaussian Process}{5}{section.2}%
\contentsline {subsection}{\numberline {2.1}Weight-space view}{5}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Standard linear model}{5}{subsubsection.2.1.1}%
\contentsline {paragraph}{Errors}{5}{equation.1}%
\contentsline {subsubsection}{\numberline {2.1.2}Determining weights}{5}{subsubsection.2.1.2}%
\contentsline {paragraph}{Frequentist regression}{5}{subsubsection.2.1.2}%
\contentsline {paragraph}{Bayesian regression}{5}{subsubsection.2.1.2}%
\contentsline {paragraph}{Deriving our posterior}{6}{equation.3}%
\contentsline {paragraph}{Deriving the properties of the posterior by completing the square}{6}{equation.8}%
\contentsline {paragraph}{Gaussian posteriors and ridge regression}{7}{equation.11}%
\contentsline {subsubsection}{\numberline {2.1.3}Predictive distribution}{7}{subsubsection.2.1.3}%
\contentsline {paragraph}{Deriving the predictive distribution}{7}{subsubsection.2.1.3}%
\contentsline {subsubsection}{\numberline {2.1.4}Projections of inputs into feature space}{9}{subsubsection.2.1.4}%
\contentsline {subsubsection}{\numberline {2.1.5}Computational issues}{9}{subsubsection.2.1.5}%
\contentsline {paragraph}{Avoiding inversion of $A_{\phi }$}{9}{subsubsection.2.1.5}%
\contentsline {paragraph}{Kernels and the kernel trick}{10}{equation.19}%
\contentsline {subsection}{\numberline {2.2}Function-space view \blx@tocontentsinit {0}\cite {gp-ml}}{10}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Gaussian processes (GP)}{10}{subsubsection.2.2.1}%
\contentsline {paragraph}{Bayesian linear model}{10}{subsubsection.2.2.1}%
\contentsline {paragraph}{Function evaluations to a random function}{10}{equation.20}%
\contentsline {paragraph}{Definition of a GP}{11}{equation.20}%
\contentsline {paragraph}{Consistency requirement}{11}{equation.20}%
\contentsline {subsubsection}{\numberline {2.2.2}Predictive distributions with noise-free observations}{11}{subsubsection.2.2.2}%
\contentsline {paragraph}{Prior distribution over functions}{11}{subsubsection.2.2.2}%
\contentsline {paragraph}{Posterior distribution of functions}{11}{equation.21}%
\contentsline {subsubsection}{\numberline {2.2.3}Predictive distributions with noisy observations}{11}{subsubsection.2.2.3}%
\contentsline {paragraph}{Noisy observations prior}{11}{subsubsection.2.2.3}%
\contentsline {paragraph}{Noisy observations posterior}{11}{subsubsection.2.2.3}%
\contentsline {subsubsection}{\numberline {2.2.4}Marginal likelihood}{12}{subsubsection.2.2.4}%
\contentsline {subsubsection}{\numberline {2.2.5}Algorithm for Gaussian processes}{12}{subsubsection.2.2.5}%
\contentsline {section}{\numberline {3}Exploring Covariance Functions}{13}{section.3}%
\contentsline {subsection}{\numberline {3.1}Characteristics of covariance functions and matrices}{13}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}Gram matrices}{13}{subsubsection.3.1.1}%
\contentsline {subsubsection}{\numberline {3.1.2}Eigenvalue and eigenfunctions of covariance matrices}{13}{subsubsection.3.1.2}%
\contentsline {paragraph}{Integral operators}{13}{subsubsection.3.1.2}%
\contentsline {paragraph}{Mercer's theorem}{14}{subsubsection.3.1.2}%
\contentsline {subsubsection}{\numberline {3.1.3}Choosing the length scale and other hyperparameters}{14}{subsubsection.3.1.3}%
\contentsline {paragraph}{Analysing the length scale}{14}{subsubsection.3.1.3}%
\contentsline {paragraph}{Length scale and upcrossings}{15}{equation.26}%
\contentsline {subsubsection}{\numberline {3.1.4}Mean square continuity and differentiability}{15}{subsubsection.3.1.4}%
\contentsline {paragraph}{Mean square space}{15}{subsubsection.3.1.4}%
\contentsline {paragraph}{MS continuity}{16}{subsubsection.3.1.4}%
\contentsline {paragraph}{MS differentiability}{16}{equation.28}%
\contentsline {subsection}{\numberline {3.2}Stationary covariance functions}{19}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}Stationarity and isotropicism}{19}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}Spectral density}{19}{subsubsection.3.2.2}%
\contentsline {paragraph}{Spectral density and MS differentiability}{20}{equation.36}%
\contentsline {subsubsection}{\numberline {3.2.3}GPs from stationary covariance functions in MS space}{20}{subsubsection.3.2.3}%
\contentsline {subsection}{\numberline {3.3}Stationary covariance functions}{20}{subsection.3.3}%
\contentsline {subsubsection}{\numberline {3.3.1}Squared exponential (SE)}{20}{subsubsection.3.3.1}%
\contentsline {paragraph}{From feature space to SE}{21}{equation.38}%
\contentsline {subsubsection}{\numberline {3.3.2}Rational quadratic (RQ)}{25}{subsubsection.3.3.2}%
\contentsline {subsubsection}{\numberline {3.3.3}$\gamma $-exponential and exponential}{28}{subsubsection.3.3.3}%
\contentsline {paragraph}{Exponential covariance function}{29}{figure.10}%
\contentsline {subsubsection}{\numberline {3.3.4}Matern-class}{31}{subsubsection.3.3.4}%
\contentsline {paragraph}{Matern 3/2}{32}{subsubsection.3.3.4}%
\contentsline {paragraph}{Matern 5/2}{33}{figure.16}%
\contentsline {section}{\numberline {4}Computational Issues}{36}{section.4}%
\contentsline {subsection}{\numberline {4.1}Cholesky decomposition}{36}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Sparse kernels}{37}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Eigenfunction and eigenvalue approximation of covariance matrices \blx@tocontentsinit {0}\cite {gp-ml}}{37}{subsection.4.3}%
\contentsline {subsubsection}{\numberline {4.3.1}Approximating $\Phi _i$ and $U_i$ with Nystrom}{37}{subsubsection.4.3.1}%
\contentsline {subsection}{\numberline {4.4}Subset-of-data (SoD) \blx@tocontentsinit {0}\cite {big-data}}{38}{subsection.4.4}%
\contentsline {subsection}{\numberline {4.5}Sparse approximations \blx@tocontentsinit {0}\cite {big-data}}{38}{subsection.4.5}%
\contentsline {subsubsection}{\numberline {4.5.1}Prior approximations}{38}{subsubsection.4.5.1}%
\contentsline {paragraph}{Subset-of-Regression (SoR) \blx@tocontentsinit {0}\cite {sor}}{38}{subsubsection.4.5.1}%
\contentsline {paragraph}{Fully independent training conditional (FITC) \blx@tocontentsinit {0}\cite {fitc}}{39}{subsubsection.4.5.1}%
\contentsline {subsubsection}{\numberline {4.5.2}Posterior approximations}{40}{subsubsection.4.5.2}%
\contentsline {paragraph}{Variational free energy (VFE)}{40}{subsubsection.4.5.2}%
\contentsline {subparagraph}{Deriving FITC through the VFE framework \blx@tocontentsinit {0}\cite {fitc-vfe-unifier}}{41}{equation.44}%
\contentsline {paragraph}{Stochastic varational GP (SVGP)}{41}{equation.44}%
\contentsline {subsection}{\numberline {4.6}Celerite kernels \blx@tocontentsinit {0}\cite {foreman-mackay}}{42}{subsection.4.6}%
\contentsline {subsubsection}{\numberline {4.6.1}The celerite model}{42}{subsubsection.4.6.1}%
\contentsline {subsubsection}{\numberline {4.6.2}Building Matern 3/2 from celerite}{42}{subsubsection.4.6.2}%
\contentsline {subsubsection}{\numberline {4.6.3}Cholesky factorisation and inversion of celerite kernels}{43}{subsubsection.4.6.3}%
\contentsline {paragraph}{Semiseperable matrices}{43}{subsubsection.4.6.3}%
\contentsline {paragraph}{Celerite kernels as semiseperable matrices}{43}{equation.47}%
\contentsline {paragraph}{Cholesky factorisation of semiseperable matrices}{44}{equation.47}%
\contentsline {paragraph}{Inversion of semiseperable matrices with a Cholesky factorisation}{44}{equation.48}%
\contentsline {section}{\numberline {5}TODO Applying a Gaussian Process to Astrostatistics}{45}{section.5}%
\contentsline {subsection}{\numberline {5.1}Introduction}{45}{subsection.5.1}%
\contentsline {subsubsection}{\numberline {5.1.1}Astrological background \blx@tocontentsinit {0}\cite {galaxy-spectra-101}}{45}{subsubsection.5.1.1}%
\contentsline {subsubsection}{\numberline {5.1.2}Using GP \blx@tocontentsinit {0}\cite {galaxy-gp-noise}}{45}{subsubsection.5.1.2}%
\contentsline {subsection}{\numberline {5.2}Methodology}{45}{subsection.5.2}%
\contentsline {subsubsection}{\numberline {5.2.1}Approaches considered}{45}{subsubsection.5.2.1}%
\contentsline {paragraph}{Stochastic variational Gaussian processes (SVGP) \blx@tocontentsinit {0}\cite {svgp}}{45}{subsubsection.5.2.1}%
\contentsline {paragraph}{Structured kernel interpolation (SKI) \blx@tocontentsinit {0}\cite {ski}}{45}{subsubsection.5.2.1}%
\contentsline {paragraph}{Celerite kernels \blx@tocontentsinit {0}\cite {foreman-mackay}}{45}{subsubsection.5.2.1}%
\contentsline {subsubsection}{\numberline {5.2.2}Computational speed}{45}{subsubsection.5.2.2}%
\contentsline {subsubsection}{\numberline {5.2.3}Accuracy}{45}{subsubsection.5.2.3}%
\contentsline {subsection}{\numberline {5.3}Results}{45}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Discussion}{45}{subsection.5.4}%
\contentsline {subsection}{\numberline {5.5}Conclusion}{45}{subsection.5.5}%
\contentsline {section}{\numberline {6}TODO Conclusion}{46}{section.6}%
