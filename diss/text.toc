\contentsline {section}{\numberline {1}Introduction}{4}{section.1}%
\contentsline {section}{\numberline {2}Defining the Gaussian Process}{5}{section.2}%
\contentsline {subsection}{\numberline {2.1}Weight-space view \blx@tocontentsinit {0}\cite {gp-ml}}{5}{subsection.2.1}%
\contentsline {subsubsection}{\numberline {2.1.1}Standard linear model}{5}{subsubsection.2.1.1}%
\contentsline {subsubsection}{\numberline {2.1.2}Determining weights}{5}{subsubsection.2.1.2}%
\contentsline {paragraph}{\numberline {2.1.2.1}Deriving our posterior}{5}{paragraph.2.1.2.1}%
\contentsline {paragraph}{\numberline {2.1.2.2}Deriving the properties of the posterior by completing the square}{6}{paragraph.2.1.2.2}%
\contentsline {paragraph}{\numberline {2.1.2.3}Gaussian posteriors and ridge regression}{6}{paragraph.2.1.2.3}%
\contentsline {subsubsection}{\numberline {2.1.3}Predictive distribution}{7}{subsubsection.2.1.3}%
\contentsline {paragraph}{\numberline {2.1.3.1}Deriving the predictive distribution}{7}{paragraph.2.1.3.1}%
\contentsline {subsubsection}{\numberline {2.1.4}Projections of inputs into feature space}{8}{subsubsection.2.1.4}%
\contentsline {subsubsection}{\numberline {2.1.5}Computational issues}{9}{subsubsection.2.1.5}%
\contentsline {paragraph}{\numberline {2.1.5.1}Avoiding inversion of $A_{\phi }$}{9}{paragraph.2.1.5.1}%
\contentsline {paragraph}{\numberline {2.1.5.2}Kernels and the kernel trick}{9}{paragraph.2.1.5.2}%
\contentsline {subsection}{\numberline {2.2}Function-space view \blx@tocontentsinit {0}\cite {gp-ml}}{10}{subsection.2.2}%
\contentsline {subsubsection}{\numberline {2.2.1}Gaussian processes (GP)}{10}{subsubsection.2.2.1}%
\contentsline {paragraph}{\numberline {2.2.1.1}Bayesian linear model}{10}{paragraph.2.2.1.1}%
\contentsline {paragraph}{\numberline {2.2.1.2}Function evaluations to a random function}{10}{paragraph.2.2.1.2}%
\contentsline {paragraph}{\numberline {2.2.1.3}Definition of a GP}{10}{paragraph.2.2.1.3}%
\contentsline {paragraph}{\numberline {2.2.1.4}Consistency requirement}{10}{paragraph.2.2.1.4}%
\contentsline {subsubsection}{\numberline {2.2.2}Predictive distributions with noise-free observations}{11}{subsubsection.2.2.2}%
\contentsline {paragraph}{\numberline {2.2.2.1}Prior distribution over functions}{11}{paragraph.2.2.2.1}%
\contentsline {paragraph}{\numberline {2.2.2.2}Posterior distribution of functions}{11}{paragraph.2.2.2.2}%
\contentsline {subsubsection}{\numberline {2.2.3}Predictive distributions with noisy observations}{11}{subsubsection.2.2.3}%
\contentsline {paragraph}{\numberline {2.2.3.1}Noisy observations prior}{11}{paragraph.2.2.3.1}%
\contentsline {paragraph}{\numberline {2.2.3.2}Noisy observations posterior}{11}{paragraph.2.2.3.2}%
\contentsline {subsubsection}{\numberline {2.2.4}Marginal likelihood}{11}{subsubsection.2.2.4}%
\contentsline {subsubsection}{\numberline {2.2.5}Algorithm for predictive distribution}{12}{subsubsection.2.2.5}%
\contentsline {paragraph}{\numberline {2.2.5.1}TODO Choelsky decomposition}{12}{paragraph.2.2.5.1}%
\contentsline {section}{\numberline {3}Exploring Covariance Functions}{13}{section.3}%
\contentsline {subsection}{\numberline {3.1}Characteristics of covariance functions \blx@tocontentsinit {0}\cite {gp-ml}}{13}{subsection.3.1}%
\contentsline {subsubsection}{\numberline {3.1.1}Covariance matrices}{13}{subsubsection.3.1.1}%
\contentsline {subsubsection}{\numberline {3.1.2}Eigenvalue analysis of covariance matrices}{13}{subsubsection.3.1.2}%
\contentsline {paragraph}{\numberline {3.1.2.1}Integral operators}{13}{paragraph.3.1.2.1}%
\contentsline {paragraph}{\numberline {3.1.2.2}Mercer's theorem}{13}{paragraph.3.1.2.2}%
\contentsline {paragraph}{\numberline {3.1.2.3}Covariance matrix approximations}{14}{paragraph.3.1.2.3}%
\contentsline {paragraph}{\numberline {3.1.2.4}Approximating $\Phi _i$ and $U_i$}{14}{paragraph.3.1.2.4}%
\contentsline {subsubsection}{\numberline {3.1.3}Varying the length scale}{14}{subsubsection.3.1.3}%
\contentsline {subsubsection}{\numberline {3.1.4}Mean square continuity and differentiability}{15}{subsubsection.3.1.4}%
\contentsline {paragraph}{\numberline {3.1.4.1}Continuity}{15}{paragraph.3.1.4.1}%
\contentsline {paragraph}{\numberline {3.1.4.2}Differentiability}{16}{paragraph.3.1.4.2}%
\contentsline {subsection}{\numberline {3.2}Stationary covariance functions \blx@tocontentsinit {0}\cite {gp-ml}}{18}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}Stationarity and isotropicism}{18}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}Spectral density}{19}{subsubsection.3.2.2}%
\contentsline {paragraph}{\numberline {3.2.2.1}Smoothness}{19}{paragraph.3.2.2.1}%
\contentsline {subsubsection}{\numberline {3.2.3}GPs from stationary covariance functions in MS space}{19}{subsubsection.3.2.3}%
\contentsline {subsection}{\numberline {3.3}Stationary covariance functions \blx@tocontentsinit {0}\cite {gp-ml}}{19}{subsection.3.3}%
\contentsline {subsubsection}{\numberline {3.3.1}Squared exponential (SE)}{19}{subsubsection.3.3.1}%
\contentsline {paragraph}{\numberline {3.3.1.1}From feature space to SE}{20}{paragraph.3.3.1.1}%
\contentsline {paragraph}{\numberline {3.3.1.2}Length scale}{20}{paragraph.3.3.1.2}%
\contentsline {subsubsection}{\numberline {3.3.2}TODO Rational quadratic (RQ)}{22}{subsubsection.3.3.2}%
\contentsline {subsubsection}{\numberline {3.3.3}$\gamma $-exponential and exponential}{23}{subsubsection.3.3.3}%
\contentsline {subsubsection}{\numberline {3.3.4}Matern-class}{25}{subsubsection.3.3.4}%
\contentsline {paragraph}{\numberline {3.3.4.1}Matern 3/2}{26}{paragraph.3.3.4.1}%
\contentsline {paragraph}{\numberline {3.3.4.2}Matern 5/2}{27}{paragraph.3.3.4.2}%
\contentsline {section}{\numberline {4}Computational Issues}{29}{section.4}%
\contentsline {subsection}{\numberline {4.1}TODO Covariance function approximations using spectral density \blx@tocontentsinit {0}\cite {foreman-mackay}}{29}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Global covariance matrix inversion approximations \blx@tocontentsinit {0}\cite {big-data}}{29}{subsection.4.2}%
\contentsline {subsubsection}{\numberline {4.2.1}Subset-of-data}{29}{subsubsection.4.2.1}%
\contentsline {subsubsection}{\numberline {4.2.2}Sparse kernels}{29}{subsubsection.4.2.2}%
\contentsline {subsubsection}{\numberline {4.2.3}TODO Sparse approximations}{29}{subsubsection.4.2.3}%
\contentsline {paragraph}{\numberline {4.2.3.1}Prior approximation}{29}{paragraph.4.2.3.1}%
\contentsline {paragraph}{\numberline {4.2.3.2}Posterior approximation}{29}{paragraph.4.2.3.2}%
\contentsline {paragraph}{\numberline {4.2.3.3}Structured sparse approximation}{29}{paragraph.4.2.3.3}%
\contentsline {subsection}{\numberline {4.3}TODO Local covariance matrix inversion approximations \blx@tocontentsinit {0}\cite {big-data}}{29}{subsection.4.3}%
\contentsline {subsubsection}{\numberline {4.3.1}Naive-local-experts}{29}{subsubsection.4.3.1}%
\contentsline {subsubsection}{\numberline {4.3.2}Mixture-of-experts}{29}{subsubsection.4.3.2}%
\contentsline {subsubsection}{\numberline {4.3.3}Product-of-experts}{29}{subsubsection.4.3.3}%
\contentsline {section}{\numberline {5}TODO Applying a Gaussian Process to Astrostatistics}{30}{section.5}%
\contentsline {subsection}{\numberline {5.1}Introduction}{30}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Methodology}{30}{subsection.5.2}%
\contentsline {subsubsection}{\numberline {5.2.1}Applying the Gaussian Process}{30}{subsubsection.5.2.1}%
\contentsline {subsubsection}{\numberline {5.2.2}Matrix inversion}{30}{subsubsection.5.2.2}%
\contentsline {subsubsection}{\numberline {5.2.3}Spectral density}{30}{subsubsection.5.2.3}%
\contentsline {subsection}{\numberline {5.3}Results}{30}{subsection.5.3}%
\contentsline {subsection}{\numberline {5.4}Discussion}{30}{subsection.5.4}%
\contentsline {subsection}{\numberline {5.5}Conclusion}{30}{subsection.5.5}%
\contentsline {section}{\numberline {6}Conclusion}{31}{section.6}%
